{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ngeva\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\ngeva\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\ngeva\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "import nltk\n",
    "import string\n",
    "nltk.download('stopwords')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.probability import FreqDist\n",
    "from wordcloud import WordCloud, ImageColorGenerator\n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation, NMF\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore')\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import pickle\n",
    "import requests\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "read csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw = pd.read_csv('pos_and_neg_tweets_final_no_dup.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_raw.loc[:,['text', 'user_followers', 'favorites', 'retweets', 'is_retweet', 'category']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"up_text\"] = df.text.str.lower()\n",
    "df.up_text = df.up_text.apply(lambda x:re.sub('@[^\\s]+','',x))\n",
    "df.up_text = df.up_text.apply(lambda x:re.sub(r'\\B#\\S+','',x))\n",
    "df.up_text = df.up_text.apply(lambda x:re.sub(r\"http\\S+\", \"\", x))\n",
    "df.up_text = df.up_text.apply(lambda x:' '.join(re.findall(r'\\w+', x)))\n",
    "df.up_text = df.up_text.apply(lambda x:re.sub(r'\\s+[a-zA-Z]\\s+', '', x))\n",
    "df.up_text = df.up_text.apply(lambda x:re.sub(r'\\s+', ' ', x, flags=re.I))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "contractions_dict = { \"ain't\": \"are not \",\"'s\":\" is \",\"aren't\": \"are not\",\n",
    "                     \"can't\": \"cannot\",\"can't've\": \"cannot have\",\n",
    "                     \"'cause\": \"because\",\"could've\": \"could have\",\"couldn't\": \"could not\",\n",
    "                     \"couldn't've\": \"could not have\", \"didn't\": \"did not\",\"doesn't\": \"does not\",\n",
    "                     \"don't\": \"do not\",\"hadn't\": \"had not\",\"hadn't've\": \"had not have\",\n",
    "                     \"hasn't\": \"has not\",\"haven't\": \"have not\",\"he'd\": \"he would\",\n",
    "                     \"he'd've\": \"he would have\",\"he'll\": \"he will\", \"he'll've\": \"he will have\",\n",
    "                     \"how'd\": \"how did\",\"how'd'y\": \"how do you\",\"how'll\": \"how will\",\n",
    "                     \"I'd\": \"I would\", \"I'd've\": \"I would have\",\"I'll\": \"I will\",\n",
    "                     \"I'll've\": \"I will have\",\"I'm\": \"I am\",\"I've\": \"I have\", \"isn't\": \"is not\",\n",
    "                     \"it'd\": \"it would\",\"it'd've\": \"it would have\",\"it'll\": \"it will\",\n",
    "                     \"it'll've\": \"it will have\", \"let's\": \"let us\",\"ma'am\": \"madam\",\n",
    "                     \"mayn't\": \"may not\",\"might've\": \"might have\",\"mightn't\": \"might not\", \n",
    "                     \"mightn't've\": \"might not have\",\"must've\": \"must have\",\"mustn't\": \"must not\",\n",
    "                     \"mustn't've\": \"must not have\", \"needn't\": \"need not\",\n",
    "                     \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\",\"oughtn't\": \"ought not\",\n",
    "                     \"oughtn't've\": \"ought not have\",\"shan't\": \"shall not\",\"sha'n't\": \"shall not\",\n",
    "                     \"shan't've\": \"shall not have\",\"she'd\": \"she would\",\"she'd've\": \"she would have\",\n",
    "                     \"she'll\": \"she will\", \"she'll've\": \"she will have\",\"should've\": \"should have\",\n",
    "                     \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\",\"so've\": \"so have\",\n",
    "                     \"that'd\": \"that would\",\"that'd've\": \"that would have\", \"there'd\": \"there would\",\n",
    "                     \"there'd've\": \"there would have\", \"they'd\": \"they would\",\n",
    "                     \"they'd've\": \"they would have\",\"they'll\": \"they will\",\n",
    "                     \"they'll've\": \"they will have\", \"they're\": \"they are\",\"they've\": \"they have\",\n",
    "                     \"to've\": \"to have\",\"wasn't\": \"was not\",\"we'd\": \"we would\",\n",
    "                     \"we'd've\": \"we would have\",\"we'll\": \"we will\",\"we'll've\": \"we will have\",\n",
    "                     \"we're\": \"we are\",\"we've\": \"we have\", \"weren't\": \"were not\",\"what'll\": \"what will\",\n",
    "                     \"what'll've\": \"what will have\",\"what're\": \"what are\", \"what've\": \"what have\",\n",
    "                     \"when've\": \"when have\",\"where'd\": \"where did\", \"where've\": \"where have\",\n",
    "                     \"who'll\": \"who will\",\"who'll've\": \"who will have\",\"who've\": \"who have\",\n",
    "                     \"why've\": \"why have\",\"will've\": \"will have\",\"won't\": \"will not\",\n",
    "                     \"won't've\": \"will not have\", \"would've\": \"would have\",\"wouldn't\": \"would not\",\n",
    "                     \"wouldn't've\": \"would not have\",\"y'all\": \"you all\", \"y'all'd\": \"you all would\",\n",
    "                     \"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\n",
    "                     \"y'all've\": \"you all have\", \"you'd\": \"you would\",\"you'd've\": \"you would have\",\n",
    "                     \"you'll\": \"you will\",\"you'll've\": \"you will have\", \"you're\": \"you are\",\n",
    "                     \"you've\": \"you have\"}\n",
    "\n",
    "contractions_re=re.compile('(%s)' % '|'.join(contractions_dict.keys()))\n",
    "\n",
    "def expand_contractions(text,contractions_dict=contractions_dict):\n",
    "    def replace(match):\n",
    "        return contractions_dict[match.group(0)]\n",
    "    return contractions_re.sub(replace, text)\n",
    "\n",
    "df['up_text']=df['up_text'].apply(lambda x:expand_contractions(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tokenized'] = df['up_text'].apply(word_tokenize)\n",
    "stop_words = set(stopwords.words('english'))\n",
    "df['tokenized'] = df['tokenized'].apply(lambda x: [word for word in x if word not in stop_words])\n",
    "df['pos_tags'] = df['tokenized'].apply(nltk.tag.pos_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wordnet_pos(tag):\n",
    "    if tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN\n",
    "    \n",
    "df['tokenized'] = df['pos_tags'].apply(lambda x: [(word, get_wordnet_pos(pos_tag)) for (word, pos_tag) in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "wnl = WordNetLemmatizer()\n",
    "df['tokenized'] = df['tokenized'].apply(lambda x: [wnl.lemmatize(word, tag) for word, tag in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['n_words'] = df['up_text'].apply(lambda x: len(x.split()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['text', 'user_followers', 'favorites', 'retweets', 'is_retweet',\n",
       "       'category', 'up_text', 'tokenized', 'pos_tags', 'n_words'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = list(df.columns)\n",
    "features.remove('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X = df[features]\n",
    "y = df['category']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123, stratify=df['category'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "finding the most common words to create features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = X_train['tokenized']\n",
    "allwords = []\n",
    "for wordlist in words:\n",
    "    allwords += wordlist\n",
    "allwords = [word for word in allwords if word !='amp']\n",
    "allwords = [word for word in allwords if word !='rt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "mostcommon = FreqDist(allwords).most_common(100)\n",
    "mostcommon = [tup[0] for tup in mostcommon]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_common_token(token):\n",
    "    new_token=[]\n",
    "    for word in token:\n",
    "        if word in mostcommon:\n",
    "            new_token.append(word)\n",
    "    return new_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['tokenized_common'] = X_train['tokenized'].apply(lambda x: most_common_token(x))\n",
    "X_test['tokenized_common'] = X_test['tokenized'].apply(lambda x: most_common_token(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "empty_tokens = X_train[(X_train['tokenized_common'].str.len() == 0)].index\n",
    "X_train = X_train.drop(empty_tokens)\n",
    "y_train = y_train.drop(empty_tokens)\n",
    "\n",
    "empty_tokens = X_test[(X_test['tokenized_common'].str.len() == 0)].index\n",
    "X_test = X_test.drop(empty_tokens)\n",
    "y_test = y_test.drop(empty_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in mostcommon:\n",
    "    X_train[word]=0\n",
    "    X_test[word]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reset_index()\n",
    "X_test = X_test.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2f8662a24f54f03840d811da5e27e59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24aad5730092476eb3bfa9e22f13bb87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for index, row in tqdm(enumerate(X_train.tokenized_common)):\n",
    "    for word in row:\n",
    "        X_train.loc[index,word] = 1\n",
    "        \n",
    "for index, row in tqdm(enumerate(X_test.tokenized_common)):\n",
    "    for word in row:\n",
    "        X_test.loc[index,word] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.replace({'Positive':0, 'Negative':1})\n",
    "X_train['is_retweet'] = X_train['is_retweet'].replace({False:0, True:1})\n",
    "\n",
    "y_test = y_test.replace({'Positive':0, 'Negative':1})\n",
    "X_test['is_retweet'] = X_test['is_retweet'].replace({False:0, True:1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop = ['text', 'up_text', 'pos_tags','tokenized','index','tokenized_common']\n",
    "X_train = X_train.drop(columns_to_drop, axis=1)\n",
    "X_test = X_test.drop(columns_to_drop, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_followers</th>\n",
       "      <th>favorites</th>\n",
       "      <th>retweets</th>\n",
       "      <th>is_retweet</th>\n",
       "      <th>n_words</th>\n",
       "      <th>vaccine</th>\n",
       "      <th>get</th>\n",
       "      <th>covid</th>\n",
       "      <th>make</th>\n",
       "      <th>today</th>\n",
       "      <th>...</th>\n",
       "      <th>like</th>\n",
       "      <th>want</th>\n",
       "      <th>use</th>\n",
       "      <th>love</th>\n",
       "      <th>well</th>\n",
       "      <th>old</th>\n",
       "      <th>moment</th>\n",
       "      <th>last</th>\n",
       "      <th>look</th>\n",
       "      <th>roll</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>491</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1525</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6333</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>755</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>246</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12485</th>\n",
       "      <td>273</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12486</th>\n",
       "      <td>602</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12487</th>\n",
       "      <td>3867</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12488</th>\n",
       "      <td>194</td>\n",
       "      <td>0</td>\n",
       "      <td>95</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12489</th>\n",
       "      <td>1050</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12490 rows Ã— 105 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       user_followers  favorites  retweets  is_retweet  n_words  vaccine  get  \\\n",
       "0                 491          0         7           1       20        0    1   \n",
       "1                1525          0       100           1       18        0    0   \n",
       "2                6333          0         1           1       23        0    0   \n",
       "3                 755          0         5           1       21        0    1   \n",
       "4                 246          0         0           0       13        0    0   \n",
       "...               ...        ...       ...         ...      ...      ...  ...   \n",
       "12485             273          0        14           1       17        0    0   \n",
       "12486             602          0        12           1       20        0    0   \n",
       "12487            3867          0        28           1       18        0    1   \n",
       "12488             194          0        95           1       14        0    1   \n",
       "12489            1050          3         1           1       18        0    0   \n",
       "\n",
       "       covid  make  today  ...  like  want  use  love  well  old  moment  \\\n",
       "0          0     0      0  ...     0     0    0     0     0    0       0   \n",
       "1          0     0      0  ...     0     0    0     0     0    0       0   \n",
       "2          0     0      0  ...     0     0    0     0     0    0       0   \n",
       "3          0     0      0  ...     0     0    0     1     0    0       0   \n",
       "4          0     0      0  ...     0     0    0     0     0    0       0   \n",
       "...      ...   ...    ...  ...   ...   ...  ...   ...   ...  ...     ...   \n",
       "12485      0     0      0  ...     0     0    0     0     0    0       0   \n",
       "12486      0     0      0  ...     0     0    0     0     0    0       0   \n",
       "12487      0     0      0  ...     0     0    0     0     0    0       0   \n",
       "12488      0     0      0  ...     0     0    0     0     0    0       0   \n",
       "12489      0     0      0  ...     0     0    0     0     0    0       0   \n",
       "\n",
       "       last  look  roll  \n",
       "0         0     0     0  \n",
       "1         0     0     0  \n",
       "2         0     0     0  \n",
       "3         0     0     1  \n",
       "4         0     0     0  \n",
       "...     ...   ...   ...  \n",
       "12485     0     0     0  \n",
       "12486     0     0     0  \n",
       "12487     0     0     0  \n",
       "12488     0     0     0  \n",
       "12489     0     0     0  \n",
       "\n",
       "[12490 rows x 105 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n",
      "[11:40:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=<generator object _BaseKFold.split at 0x0000021032D142E0>,\n",
       "                   estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                           colsample_bylevel=None,\n",
       "                                           colsample_bynode=None,\n",
       "                                           colsample_bytree=None, gamma=None,\n",
       "                                           gpu_id=None, importance_type='gain',\n",
       "                                           interaction_constraints=None,\n",
       "                                           learning_rate=None,\n",
       "                                           max_delta_step=None, max_depth=None,\n",
       "                                           min_child_weight=None, mis...\n",
       "                                           random_state=None, reg_alpha=None,\n",
       "                                           reg_lambda=None,\n",
       "                                           scale_pos_weight=None,\n",
       "                                           subsample=None, tree_method=None,\n",
       "                                           validate_parameters=None,\n",
       "                                           verbosity=None),\n",
       "                   n_iter=5, n_jobs=4,\n",
       "                   param_distributions={'colsample_bytree': [0.5, 0.7, 1],\n",
       "                                        'eta': [0.05, 0.1, 0.15, 0.2, 0.25,\n",
       "                                                0.3],\n",
       "                                        'gamma': [0.0, 0.1, 0.2, 0.3, 0.4],\n",
       "                                        'max_depth': [3, 4, 5, 6, 8, 10],\n",
       "                                        'min_child_weight': [1, 2, 3, 5]},\n",
       "                   random_state=1001, scoring='roc_auc', verbose=3)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "xgb = XGBClassifier()\n",
    "\n",
    "folds = 3\n",
    "param_comb = 5\n",
    "skf = StratifiedKFold(n_splits=folds, shuffle = True, random_state = 1001)\n",
    "\n",
    "parameters = {\n",
    "     \"eta\"              : [0.05, 0.10, 0.15, 0.20, 0.25, 0.30 ] ,\n",
    "     \"max_depth\"        : [ 3, 4, 5, 6, 8, 10],\n",
    "     \"min_child_weight\" : [ 1, 2, 3, 5 ],\n",
    "     \"gamma\"            : [ 0.0, 0.1, 0.2 , 0.3, 0.4 ],\n",
    "     \"colsample_bytree\" : [0.5 , 0.7, 1]\n",
    "     }\n",
    "\n",
    "\n",
    "random_search = RandomizedSearchCV(xgb, param_distributions=parameters, \n",
    "                                   n_iter=param_comb, \n",
    "                                   scoring='roc_auc',\n",
    "                                   n_jobs=4, \n",
    "                                   cv=skf.split(X_train,y_train), \n",
    "                                   verbose=3, \n",
    "                                   random_state=1001 )\n",
    "\n",
    "random_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " All results:\n",
      "{'mean_fit_time': array([15.4233319 , 17.56327097,  7.8975997 ,  6.00443824,  5.33672508]), 'std_fit_time': array([0.16277232, 2.81061986, 0.92422325, 0.17206398, 1.33254377]), 'mean_score_time': array([0.08900166, 0.0803322 , 0.06233525, 0.05400236, 0.04310322]), 'std_score_time': array([0.01512163, 0.01746138, 0.01681769, 0.00725765, 0.00244675]), 'param_min_child_weight': masked_array(data=[2, 3, 5, 1, 1],\n",
      "             mask=[False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_max_depth': masked_array(data=[6, 10, 5, 4, 5],\n",
      "             mask=[False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_gamma': masked_array(data=[0.0, 0.1, 0.4, 0.3, 0.4],\n",
      "             mask=[False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_eta': masked_array(data=[0.25, 0.15, 0.1, 0.25, 0.25],\n",
      "             mask=[False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_colsample_bytree': masked_array(data=[0.7, 0.5, 0.5, 1, 1],\n",
      "             mask=[False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'min_child_weight': 2, 'max_depth': 6, 'gamma': 0.0, 'eta': 0.25, 'colsample_bytree': 0.7}, {'min_child_weight': 3, 'max_depth': 10, 'gamma': 0.1, 'eta': 0.15, 'colsample_bytree': 0.5}, {'min_child_weight': 5, 'max_depth': 5, 'gamma': 0.4, 'eta': 0.1, 'colsample_bytree': 0.5}, {'min_child_weight': 1, 'max_depth': 4, 'gamma': 0.3, 'eta': 0.25, 'colsample_bytree': 1}, {'min_child_weight': 1, 'max_depth': 5, 'gamma': 0.4, 'eta': 0.25, 'colsample_bytree': 1}], 'split0_test_score': array([0.96569012, 0.96670824, 0.94498504, 0.95949601, 0.96427315]), 'split1_test_score': array([0.9681898 , 0.96744891, 0.94628166, 0.96029688, 0.96624637]), 'split2_test_score': array([0.96543894, 0.96253761, 0.94024882, 0.95898821, 0.96377461]), 'mean_test_score': array([0.96643962, 0.96556492, 0.9438385 , 0.9595937 , 0.96476471]), 'std_test_score': array([0.00124181, 0.00216188, 0.0025929 , 0.00053871, 0.00106728]), 'rank_test_score': array([1, 2, 5, 4, 3])}\n",
      "\n",
      " Best estimator:\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=0.7, eta=0.25, gamma=0.0,\n",
      "              gpu_id=-1, importance_type='gain', interaction_constraints='',\n",
      "              learning_rate=0.25, max_delta_step=0, max_depth=6,\n",
      "              min_child_weight=2, missing=nan, monotone_constraints='()',\n",
      "              n_estimators=100, n_jobs=4, num_parallel_tree=1, random_state=0,\n",
      "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
      "              tree_method='exact', validate_parameters=1, verbosity=None)\n",
      "\n",
      " Best normalized gini score for 3-fold search with 5 parameter combinations:\n",
      "0.9328792375028421\n",
      "\n",
      " Best hyperparameters:\n",
      "{'min_child_weight': 2, 'max_depth': 6, 'gamma': 0.0, 'eta': 0.25, 'colsample_bytree': 0.7}\n"
     ]
    }
   ],
   "source": [
    "print('\\n All results:')\n",
    "print(random_search.cv_results_)\n",
    "print('\\n Best estimator:')\n",
    "print(random_search.best_estimator_)\n",
    "print('\\n Best normalized gini score for %d-fold search with %d parameter combinations:' % (folds, param_comb))\n",
    "print(random_search.best_score_ * 2 - 1)\n",
    "print('\\n Best hyperparameters:')\n",
    "print(random_search.best_params_)\n",
    "results = pd.DataFrame(random_search.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = random_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"xgboost.sav\"\n",
    "pickle.dump(model, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision = 0.9206919060052219\n",
      "Recall = 0.8905764714794333\n",
      "Accuracy = 0.9226075786769429\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, confusion_matrix, roc_auc_score, classification_report\n",
    "preds = random_search.predict_proba(X_test)\n",
    "best_preds = np.asarray([np.argmax(line) for line in preds])\n",
    "\n",
    "print(\"Precision = {}\".format(precision_score(y_test, best_preds, average='macro')))\n",
    "print(\"Recall = {}\".format(recall_score(y_test, best_preds, average='macro')))\n",
    "print(\"Accuracy = {}\".format(accuracy_score(y_test, best_preds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "prec = round(precision_score(y_test, best_preds, average='macro'),2)\n",
    "recall = round(recall_score(y_test, best_preds, average='macro'),2)\n",
    "acc = round(accuracy_score(y_test, best_preds),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(np.array(y_test), best_preds).ravel()\n",
    "fpr = fp/(fp+tn)\n",
    "tpr = tp/(tp+fn)\n",
    "auc = roc_auc_score(y_test, preds[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_test, preds[:,1])\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "display = metrics.RocCurveDisplay(fpr=fpr, tpr=tpr, roc_auc=roc_auc, estimator_name='xgboost')\n",
    "display.plot() \n",
    "plt.plot([0,1],[0,1], ls= '--', label = 'ROC curve (area = %0.2f)' % auc)\n",
    "plt.title('XGboost classifier\\n accuray={}, precision={}, recall={}'.format(acc,prec,recall))\n",
    "plt.show()      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "non-anvi-vax       0.92      0.97      0.95      2193\n",
      "    anti-vax       0.92      0.81      0.86       921\n",
      "\n",
      "    accuracy                           0.92      3114\n",
      "   macro avg       0.92      0.89      0.90      3114\n",
      "weighted avg       0.92      0.92      0.92      3114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "target_names = ['non-anvi-vax', 'anti-vax']\n",
    "print(classification_report(y_test, best_preds, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.00108578, 0.00868621, 0.01085776, 0.02171553,\n",
       "       0.02931596, 0.03040174, 0.03365907, 0.03908795, 0.04343105,\n",
       "       0.04560261, 0.04668838, 0.04885993, 0.05211726, 0.05428882,\n",
       "       0.05754615, 0.06188925, 0.07926167, 0.15200869, 0.15743757,\n",
       "       0.1606949 , 0.16286645, 0.16612378, 0.16938111, 0.17155266,\n",
       "       0.17263844, 0.17480999, 0.17915309, 0.18132465, 0.18675353,\n",
       "       0.19652552, 0.19869707, 0.2019544 , 0.2062975 , 0.20738328,\n",
       "       0.21064061, 0.21606949, 0.21715527, 0.24429967, 0.24972856,\n",
       "       0.25190011, 0.25841477, 0.26058632, 0.26927253, 0.27144408,\n",
       "       0.27361564, 0.27578719, 0.27904452, 0.28121607, 0.28555917,\n",
       "       0.28773073, 0.29424539, 0.29750271, 0.3029316 , 0.31161781,\n",
       "       0.31487514, 0.31921824, 0.32247557, 0.32356135, 0.3257329 ,\n",
       "       0.32790445, 0.330076  , 0.33116178, 0.33659066, 0.33876221,\n",
       "       0.34961998, 0.35613464, 0.35722041, 0.36047774, 0.3713355 ,\n",
       "       0.38436482, 0.38653637, 0.38870793, 0.3897937 , 0.39739414,\n",
       "       0.39956569, 0.40390879, 0.40716612, 0.4082519 , 0.41259501,\n",
       "       0.41368078, 0.42128122, 0.42345277, 0.42453855, 0.4267101 ,\n",
       "       0.42888165, 0.4310532 , 0.43213898, 0.44082519, 0.4451683 ,\n",
       "       0.4495114 , 0.45168295, 0.45385451, 0.45494028, 0.46145494,\n",
       "       0.46362649, 0.47339848, 0.47774159, 0.48099891, 0.50705755,\n",
       "       0.50705755, 0.5092291 , 0.51791531, 0.52117264, 0.52334419,\n",
       "       0.53420195, 0.53854506, 0.53854506, 0.54071661, 0.54505972,\n",
       "       0.54723127, 0.5548317 , 0.55700326, 0.56243214, 0.56460369,\n",
       "       0.5689468 , 0.5689468 , 0.57437568, 0.57437568, 0.58089034,\n",
       "       0.58089034, 0.58197611, 0.58414767, 0.58414767, 0.58631922,\n",
       "       0.58849077, 0.59066232, 0.59283388, 0.59283388, 0.59391965,\n",
       "       0.59609121, 0.59934853, 0.59934853, 0.60369164, 0.60586319,\n",
       "       0.60586319, 0.60803474, 0.6102063 , 0.61237785, 0.61237785,\n",
       "       0.61780673, 0.61780673, 0.62106406, 0.62975027, 0.62975027,\n",
       "       0.63192182, 0.63626493, 0.63843648, 0.64169381, 0.64386536,\n",
       "       0.64386536, 0.64603692, 0.64603692, 0.65363735, 0.65363735,\n",
       "       0.65689468, 0.65689468, 0.66123779, 0.66123779, 0.66883822,\n",
       "       0.67318132, 0.67318132, 0.6742671 , 0.6742671 , 0.67535288,\n",
       "       0.67861021, 0.68186754, 0.68512486, 0.68729642, 0.69163952,\n",
       "       0.69381107, 0.69381107, 0.69923996, 0.70141151, 0.7111835 ,\n",
       "       0.71226927, 0.71444083, 0.71878393, 0.71878393, 0.72312704,\n",
       "       0.72312704, 0.72529859, 0.72638436, 0.72638436, 0.72855592,\n",
       "       0.72855592, 0.73181325, 0.73507058, 0.74158523, 0.74158523,\n",
       "       0.74267101, 0.74267101, 0.74375679, 0.74375679, 0.74809989,\n",
       "       0.74809989, 0.74918567, 0.74918567, 0.75135722, 0.75135722,\n",
       "       0.75461455, 0.75461455, 0.7567861 , 0.7567861 , 0.75895765,\n",
       "       0.76221498, 0.76221498, 0.76330076, 0.76330076, 0.77633008,\n",
       "       0.77633008, 0.77850163, 0.78067318, 0.78067318, 0.78284473,\n",
       "       0.78284473, 0.78501629, 0.78610206, 0.78610206, 0.78718784,\n",
       "       0.78718784, 0.78935939, 0.79153094, 0.79153094, 0.79261672,\n",
       "       0.79261672, 0.79587405, 0.79587405, 0.79695983, 0.79913138,\n",
       "       0.80130293, 0.80130293, 0.80238871, 0.80238871, 0.80456026,\n",
       "       0.80673181, 0.80673181, 0.80890337, 0.80998914, 0.80998914,\n",
       "       0.81324647, 0.81324647, 0.81541802, 0.81541802, 0.81976113,\n",
       "       0.81976113, 0.82084691, 0.82301846, 0.82301846, 0.82519001,\n",
       "       0.82953312, 0.82953312, 0.83170467, 0.83387622, 0.834962  ,\n",
       "       0.834962  , 0.83713355, 0.83713355, 0.84039088, 0.84039088,\n",
       "       0.84256243, 0.84364821, 0.84364821, 0.84473398, 0.84473398,\n",
       "       0.84581976, 0.84581976, 0.84690554, 0.84690554, 0.85124864,\n",
       "       0.85124864, 0.8534202 , 0.8534202 , 0.85450597, 0.85450597,\n",
       "       0.85667752, 0.85667752, 0.85884908, 0.85884908, 0.86319218,\n",
       "       0.86319218, 0.86319218, 0.86536374, 0.86536374, 0.86753529,\n",
       "       0.86862106, 0.86862106, 0.87079262, 0.87079262, 0.87296417,\n",
       "       0.87296417, 0.8762215 , 0.8762215 , 0.87730727, 0.87730727,\n",
       "       0.87839305, 0.87839305, 0.87947883, 0.8805646 , 0.8805646 ,\n",
       "       0.88273616, 0.88273616, 0.88382193, 0.88382193, 0.88490771,\n",
       "       0.88490771, 0.88599349, 0.88599349, 0.88707926, 0.88707926,\n",
       "       0.88816504, 0.88816504, 0.88925081, 0.88925081, 0.89033659,\n",
       "       0.89033659, 0.89142237, 0.89142237, 0.8946797 , 0.8946797 ,\n",
       "       0.89685125, 0.89685125, 0.90119435, 0.90119435, 0.90228013,\n",
       "       0.90228013, 0.90336591, 0.90336591, 0.90553746, 0.90553746,\n",
       "       0.90662324, 0.90662324, 0.90770901, 0.90770901, 0.90988056,\n",
       "       0.90988056, 0.91205212, 0.91205212, 0.91422367, 0.91422367,\n",
       "       0.91530945, 0.91530945, 0.917481  , 0.917481  , 0.91856678,\n",
       "       0.91856678, 0.92073833, 0.92073833, 0.9218241 , 0.9218241 ,\n",
       "       0.92290988, 0.92290988, 0.92399566, 0.92399566, 0.92616721,\n",
       "       0.92616721, 0.92725299, 0.92725299, 0.92833876, 0.92833876,\n",
       "       0.92942454, 0.92942454, 0.93051031, 0.93051031, 0.93268187,\n",
       "       0.93268187, 0.93376764, 0.93376764, 0.93485342, 0.93485342,\n",
       "       0.93702497, 0.93702497, 0.93811075, 0.93811075, 0.93811075,\n",
       "       0.93919653, 0.93919653, 0.94136808, 0.94136808, 0.94245385,\n",
       "       0.94245385, 0.94353963, 0.94353963, 0.94571118, 0.94571118,\n",
       "       0.94788274, 0.94788274, 0.94788274, 0.95005429, 0.95005429,\n",
       "       0.95114007, 0.95114007, 0.95114007, 0.95114007, 0.95331162,\n",
       "       0.95331162, 0.95331162, 0.95331162, 0.95548317, 0.95548317,\n",
       "       0.95548317, 0.95656895, 0.95656895, 0.9587405 , 0.9587405 ,\n",
       "       0.96091205, 0.96091205, 0.96199783, 0.96199783, 0.96199783,\n",
       "       0.96199783, 0.9630836 , 0.9630836 , 0.9630836 , 0.96416938,\n",
       "       0.96416938, 0.96525516, 0.96525516, 0.96742671, 0.96742671,\n",
       "       0.96742671, 0.96742671, 0.96851249, 0.96851249, 0.96959826,\n",
       "       0.96959826, 0.96959826, 0.97068404, 0.97068404, 0.97176982,\n",
       "       0.97176982, 0.97285559, 0.97285559, 0.97394137, 0.97394137,\n",
       "       0.97502714, 0.97502714, 0.97611292, 0.97611292, 0.9771987 ,\n",
       "       0.9771987 , 0.9771987 , 0.9771987 , 0.9771987 , 0.9771987 ,\n",
       "       0.97828447, 0.97828447, 0.97937025, 0.97937025, 0.97937025,\n",
       "       0.97937025, 0.97937025, 0.97937025, 0.98045603, 0.98045603,\n",
       "       0.98045603, 0.98045603, 0.98045603, 0.98045603, 0.9815418 ,\n",
       "       0.9815418 , 0.98262758, 0.98262758, 0.98371336, 0.98371336,\n",
       "       0.98371336, 0.98371336, 0.98479913, 0.98479913, 0.98588491,\n",
       "       0.98588491, 0.98588491, 0.98588491, 0.98697068, 0.98697068,\n",
       "       0.98697068, 0.98805646, 0.98805646, 0.98805646, 0.98805646,\n",
       "       0.98805646, 0.98805646, 0.98805646, 0.98805646, 0.98805646,\n",
       "       0.98805646, 0.98805646, 0.98805646, 0.98914224, 0.98914224,\n",
       "       0.98914224, 0.98914224, 0.98914224, 0.98914224, 0.98914224,\n",
       "       0.98914224, 0.99022801, 0.99022801, 0.99022801, 0.99022801,\n",
       "       0.99022801, 0.99022801, 0.99022801, 0.99022801, 0.99022801,\n",
       "       0.99022801, 0.99022801, 0.99022801, 0.99131379, 0.99131379,\n",
       "       0.99131379, 0.99131379, 0.99131379, 0.99131379, 0.99131379,\n",
       "       0.99131379, 0.99131379, 0.99131379, 0.99239957, 0.99239957,\n",
       "       0.99348534, 0.99348534, 0.99348534, 0.99348534, 0.99348534,\n",
       "       0.99348534, 0.99348534, 0.99348534, 0.99348534, 0.99348534,\n",
       "       0.99348534, 0.99457112, 0.99457112, 0.99565689, 0.99565689,\n",
       "       0.99565689, 0.99565689, 0.99565689, 0.99565689, 0.99565689,\n",
       "       0.99565689, 0.99565689, 0.99565689, 0.99565689, 0.99565689,\n",
       "       0.99565689, 0.99565689, 0.99565689, 0.99565689, 0.99565689,\n",
       "       0.99565689, 0.99565689, 0.99674267, 0.99674267, 0.99674267,\n",
       "       0.99674267, 0.99674267, 0.99782845, 0.99782845, 0.99782845,\n",
       "       0.99782845, 0.99782845, 0.99782845, 0.99891422, 0.99891422,\n",
       "       0.99891422, 0.99891422, 0.99891422, 0.99891422, 0.99891422,\n",
       "       0.99891422, 0.99891422, 0.99891422, 0.99891422, 0.99891422,\n",
       "       0.99891422, 0.99891422, 0.99891422, 0.99891422, 0.99891422,\n",
       "       0.99891422, 0.99891422, 0.99891422, 0.99891422, 0.99891422,\n",
       "       0.99891422, 0.99891422, 0.99891422, 0.99891422, 0.99891422,\n",
       "       0.99891422, 0.99891422, 0.99891422, 0.99891422, 0.99891422,\n",
       "       0.99891422, 0.99891422, 0.99891422, 0.99891422, 0.99891422,\n",
       "       0.99891422, 0.99891422, 0.99891422, 0.99891422, 0.99891422,\n",
       "       0.99891422, 0.99891422, 0.99891422, 0.99891422, 0.99891422,\n",
       "       0.99891422, 0.99891422, 0.99891422, 0.99891422, 0.99891422,\n",
       "       0.99891422, 0.99891422, 0.99891422, 0.99891422, 0.99891422,\n",
       "       0.99891422, 0.99891422, 0.99891422, 0.99891422, 0.99891422,\n",
       "       0.99891422, 0.99891422, 0.99891422, 0.99891422, 0.99891422,\n",
       "       0.99891422, 0.99891422, 0.99891422, 0.99891422, 0.99891422,\n",
       "       0.99891422, 0.99891422, 0.99891422, 0.99891422, 0.99891422,\n",
       "       0.99891422, 0.99891422, 0.99891422, 0.99891422, 0.99891422,\n",
       "       0.99891422, 0.99891422, 0.99891422, 0.99891422, 0.99891422,\n",
       "       0.99891422, 0.99891422, 0.99891422, 0.99891422, 0.99891422,\n",
       "       0.99891422, 0.99891422, 0.99891422, 0.99891422, 0.99891422,\n",
       "       0.99891422, 0.99891422, 0.99891422, 0.99891422, 0.99891422,\n",
       "       0.99891422, 0.99891422, 0.99891422, 0.99891422, 0.99891422,\n",
       "       0.99891422, 0.99891422, 0.99891422, 0.99891422, 0.99891422,\n",
       "       0.99891422, 0.99891422, 0.99891422, 0.99891422, 0.99891422,\n",
       "       0.99891422, 0.99891422, 0.99891422, 0.99891422, 0.99891422,\n",
       "       0.99891422, 0.99891422, 0.99891422, 0.99891422, 0.99891422,\n",
       "       0.99891422, 0.99891422, 0.99891422, 0.99891422, 0.99891422,\n",
       "       0.99891422, 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        ])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tpr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
